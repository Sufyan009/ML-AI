{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f18848f8-3bfa-45cf-8685-a665febab8ec",
   "metadata": {},
   "source": [
    "Evaluation techniques are critical for assessing the performance of machine learning models and interpreting how well they fit and predict data. Letâ€™s go over each technique with an explanation, examples, and sample code.\n",
    "\n",
    "### 1. **Mean Squared Error (MSE)**\n",
    "   **Description**: Measures the average squared difference between actual and predicted values. It penalizes larger errors more heavily.\n",
    "\n",
    "   \\[\n",
    "   \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
    "   \\]\n",
    "\n",
    "   **Example**:\n",
    "   ```python\n",
    "   from sklearn.metrics import mean_squared_error\n",
    "   y_true = [3, -0.5, 2, 7]\n",
    "   y_pred = [2.5, 0.0, 2, 8]\n",
    "   mse = mean_squared_error(y_true, y_pred)\n",
    "   print(\"MSE:\", mse)\n",
    "   ```\n",
    "   \n",
    "### 2. **Mean Absolute Error (MAE)**\n",
    "   **Description**: Represents the average absolute difference between actual and predicted values, less sensitive to outliers.\n",
    "\n",
    "   \\[\n",
    "   \\text{MAE} = \\frac{1}{n} \\sum_{i=1}^n |y_i - \\hat{y}_i|\n",
    "   \\]\n",
    "\n",
    "   **Example**:\n",
    "   ```python\n",
    "   from sklearn.metrics import mean_absolute_error\n",
    "   mae = mean_absolute_error(y_true, y_pred)\n",
    "   print(\"MAE:\", mae)\n",
    "   ```\n",
    "\n",
    "### 3. **Root Mean Squared Error (RMSE)**\n",
    "   **Description**: The square root of MSE, retaining the same units as the target variable, and is sensitive to outliers.\n",
    "\n",
    "   \\[\n",
    "   \\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2}\n",
    "   \\]\n",
    "\n",
    "   **Example**:\n",
    "   ```python\n",
    "   import numpy as np\n",
    "   rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "   print(\"RMSE:\", rmse)\n",
    "   ```\n",
    "\n",
    "### 4. **R2 Score and Adjusted R2 Score**\n",
    "   **R2 Score**: Measures the proportion of variance explained by the model.\n",
    "\n",
    "   \\[\n",
    "   R^2 = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\n",
    "   \\]\n",
    "\n",
    "   **Adjusted R2**: Adjusts R2 for the number of predictors, penalizing for overfitting.\n",
    "\n",
    "   \\[\n",
    "   R^2_{\\text{adj}} = 1 - \\left(1 - R^2\\right) \\frac{n - 1}{n - p - 1}\n",
    "   \\]\n",
    "\n",
    "   **Example**:\n",
    "   ```python\n",
    "   from sklearn.metrics import r2_score\n",
    "   r2 = r2_score(y_true, y_pred)\n",
    "   print(\"R2 Score:\", r2)\n",
    "   ```\n",
    "\n",
    "### 5. **Cross-Validation**\n",
    "   **Description**: Evaluates model performance by dividing data into training and testing subsets multiple times.\n",
    "\n",
    "   **Example**:\n",
    "   ```python\n",
    "   from sklearn.model_selection import cross_val_score\n",
    "   from sklearn.linear_model import LinearRegression\n",
    "   model = LinearRegression()\n",
    "   scores = cross_val_score(model, X, y, cv=5)\n",
    "   print(\"Cross-Validation Scores:\", scores)\n",
    "   ```\n",
    "\n",
    "### 6. **Accuracy, Precision, Recall**\n",
    "   - **Accuracy**: Fraction of correctly predicted instances out of total instances.\n",
    "   - **Precision**: Ratio of true positives to total predicted positives.\n",
    "   - **Recall**: Ratio of true positives to actual positives.\n",
    "\n",
    "   **Example**:\n",
    "   ```python\n",
    "   from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "   accuracy = accuracy_score(y_true, y_pred)\n",
    "   precision = precision_score(y_true, y_pred)\n",
    "   recall = recall_score(y_true, y_pred)\n",
    "   print(\"Accuracy:\", accuracy)\n",
    "   print(\"Precision:\", precision)\n",
    "   print(\"Recall:\", recall)\n",
    "   ```\n",
    "\n",
    "### 7. **F1-Score**\n",
    "   **Description**: The harmonic mean of precision and recall, useful for imbalanced classes.\n",
    "\n",
    "   \\[\n",
    "   \\text{F1} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "   \\]\n",
    "\n",
    "   **Example**:\n",
    "   ```python\n",
    "   from sklearn.metrics import f1_score\n",
    "   f1 = f1_score(y_true, y_pred)\n",
    "   print(\"F1 Score:\", f1)\n",
    "   ```\n",
    "\n",
    "### 8. **ROC Curve**\n",
    "   **Description**: Graph showing the performance of a classifier across all thresholds, plotting True Positive Rate vs. False Positive Rate.\n",
    "\n",
    "   **Example**:\n",
    "   ```python\n",
    "   from sklearn.metrics import roc_curve, auc\n",
    "   import matplotlib.pyplot as plt\n",
    "\n",
    "   fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "   roc_auc = auc(fpr, tpr)\n",
    "   plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (area = {roc_auc:.2f})')\n",
    "   plt.xlabel('False Positive Rate')\n",
    "   plt.ylabel('True Positive Rate')\n",
    "   plt.legend()\n",
    "   plt.show()\n",
    "   ```\n",
    "\n",
    "### Suggested YouTube Videos:\n",
    "- **In English**: [StatQuest: Model Evaluation Metrics](https://www.youtube.com/watch?v=HdRlS2F6Iqw) by StatQuest with Josh Starmer.\n",
    "- **In Hindi**: [Codebasics: Model Evaluation Metrics](https://www.youtube.com/watch?v=gJo0uNL-5Qw) by Codebasics.\n",
    "\n",
    "These evaluation techniques ensure models are not just accurate but robust, interpretable, and suitable for real-world application. Each metric, from MSE to ROC curves, offers unique insights into model strengths and areas for improvement, making them indispensable in machine learning and data science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b752a0b-f523-479a-8ccc-d9360fa12621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
